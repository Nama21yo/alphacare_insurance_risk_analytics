{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5401daea",
   "metadata": {},
   "source": [
    "Loading and Inspecting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac55c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './data/MachineLearningRating_v3.txt'\n",
    "\n",
    "try:\n",
    "    # 'on_bad_lines' skips rows with parsing errors.\n",
    "    # 'encoding' helps with special characters.\n",
    "    # 'low_memory=False' can help with mixed data type issues in large files.\n",
    "    df = pd.read_csv(file_path, sep='\\t', on_bad_lines='skip', encoding='latin1', low_memory=False)\n",
    "    \n",
    "    print(\"--- Data Loaded Successfully ---\")\n",
    "    print(f\"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "    \n",
    "    # Display the first few rows to get a feel for the data\n",
    "    print(\"\\n--- First 5 Rows of the Dataset ---\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Display column names and data types\n",
    "    print(\"\\n--- Dataset Info ---\")\n",
    "    df.info()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please ensure it's in the correct directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c202c",
   "metadata": {},
   "source": [
    "Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Starting Step 2: Data Cleaning and Feature Engineering ---\")\n",
    "\n",
    "# 1. Convert key numeric columns to numbers, coercing errors to 'Not a Number' (NaN)\n",
    "df['TotalClaims'] = pd.to_numeric(df['TotalClaims'], errors='coerce')\n",
    "df['TotalPremium'] = pd.to_numeric(df['TotalPremium'], errors='coerce')\n",
    "\n",
    "# 2. Drop rows where these key columns are missing, as they are crucial for analysis\n",
    "df.dropna(subset=['TotalClaims', 'TotalPremium'], inplace=True)\n",
    "\n",
    "# 3. Engineer 'HasClaim' feature: 1 if a claim was made, 0 otherwise. This is our primary risk indicator.\n",
    "df['HasClaim'] = (df['TotalClaims'] > 0).astype(int)\n",
    "\n",
    "# 4. Engineer 'Margin' feature: This represents the profit or loss on a policy.\n",
    "df['Margin'] = df['TotalPremium'] - df['TotalClaims']\n",
    "\n",
    "# 5. Clean key categorical columns for consistency\n",
    "for col in ['Gender', 'Province', 'PostalCode']:\n",
    "    if col in df.columns:\n",
    "        df.dropna(subset=[col], inplace=True)\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "print(\"--- Data Cleaning and Feature Engineering Complete ---\")\n",
    "print(f\"Dataset shape after cleaning: {df.shape}\")\n",
    "print(\"New columns 'HasClaim' and 'Margin' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b88fbb",
   "metadata": {},
   "source": [
    "Hypothesis Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffe0fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "alpha = 0.05\n",
    "print(f\"\\n--- Starting Test 1: Risk Differences Across Provinces (alpha={alpha}) ---\")\n",
    "\n",
    "if 'Province' in df.columns and df['Province'].nunique() > 1:\n",
    "    # Create a contingency table (crosstab) of Province vs. HasClaim\n",
    "    contingency_table_province = pd.crosstab(df['Province'], df['HasClaim'])\n",
    "    \n",
    "    # Perform the Chi-Squared test\n",
    "    chi2, p_value, _, _ = stats.chi2_contingency(contingency_table_province)\n",
    "    \n",
    "    print(f\"Chi-Squared Statistic: {chi2:.2f}, P-value: {p_value}\")\n",
    "    \n",
    "    # Interpret the result\n",
    "    if p_value < alpha:\n",
    "        print(\"\\nConclusion: Reject the null hypothesis.\")\n",
    "        print(\"Finding: There is a statistically significant difference in claim risk across provinces.\")\n",
    "        print(\"Recommendation: Prioritize marketing in lower-risk provinces and review underwriting rules for higher-risk ones.\")\n",
    "    else:\n",
    "        print(\"\\nConclusion: Fail to reject the null hypothesis.\")\n",
    "        print(\"Finding: There is no statistically significant evidence that risk differs by province.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc446663",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Starting Test 2: Risk Differences Between Zip Codes (alpha={alpha}) ---\")\n",
    "\n",
    "if 'PostalCode' in df.columns and df['PostalCode'].nunique() > 1:\n",
    "    # Identify the top 20 zip codes with the most policies\n",
    "    top_zipcodes = df['PostalCode'].value_counts().nlargest(20).index\n",
    "    df_top_zips = df[df['PostalCode'].isin(top_zipcodes)]\n",
    "    \n",
    "    # Create the contingency table for these top zip codes\n",
    "    contingency_table_zip = pd.crosstab(df_top_zips['PostalCode'], df_top_zips['HasClaim'])\n",
    "    \n",
    "    # Perform the test\n",
    "    chi2, p_value, _, _ = stats.chi2_contingency(contingency_table_zip)\n",
    "    \n",
    "    print(f\"Chi-Squared Statistic (top 20 zips): {chi2:.2f}, P-value: {p_value}\")\n",
    "    \n",
    "    if p_value < alpha:\n",
    "        print(\"\\nConclusion: Reject the null hypothesis.\")\n",
    "        print(\"Finding: There is a significant difference in claim risk even at the zip code level.\")\n",
    "        print(\"Recommendation: Develop location-based risk profiles for more accurate premium pricing and targeted marketing.\")\n",
    "    else:\n",
    "        print(\"\\nConclusion: Fail to reject the null hypothesis.\")\n",
    "        print(\"Finding: No significant evidence of risk differences among the top 20 zip codes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73184af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5 Code ---\n",
    "print(f\"\\n--- Starting Test 3: Margin Differences Between Zip Codes (alpha={alpha}) ---\")\n",
    "\n",
    "if 'PostalCode' in df.columns and 'df_top_zips' in locals():\n",
    "    # Create a list of margin values for each of the top 20 zip codes\n",
    "    groups = [df_top_zips['Margin'][df_top_zips['PostalCode'] == zip_code] for zip_code in top_zipcodes]\n",
    "    \n",
    "    # Perform the ANOVA test\n",
    "    f_stat, p_value = stats.f_oneway(*groups)\n",
    "    \n",
    "    print(f\"F-Statistic (top 20 zips): {f_stat:.2f}, P-value: {p_value}\")\n",
    "\n",
    "    if p_value < alpha:\n",
    "        print(\"\\nConclusion: Reject the null hypothesis.\")\n",
    "        print(\"Finding: There is a significant difference in profitability across top zip codes.\")\n",
    "        print(\"Recommendation: Analyze zip codes with low margins to check if premiums are too low or claims are too high. High-margin areas are safe markets for expansion.\")\n",
    "    else:\n",
    "        print(\"\\nConclusion: Fail to reject the null hypothesis.\")\n",
    "        print(\"Finding: No significant evidence of profitability differences among top zip codes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69cf07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6 Code ---\n",
    "print(f\"\\n--- Starting Test 4: Risk Differences Between Genders (alpha={alpha}) ---\")\n",
    "\n",
    "if 'Gender' in df.columns:\n",
    "    # Standardize gender to 'M' and 'F' for a clean comparison\n",
    "    df['Gender_Clean'] = df['Gender'].str.upper().str[0]\n",
    "    df_gender_filtered = df[df['Gender_Clean'].isin(['M', 'F'])]\n",
    "    \n",
    "    if df_gender_filtered['Gender_Clean'].nunique() == 2:\n",
    "        contingency_table_gender = pd.crosstab(df_gender_filtered['Gender_Clean'], df_gender_filtered['HasClaim'])\n",
    "        print(\"Contingency Table (Gender vs. HasClaim):\")\n",
    "        print(contingency_table_gender)\n",
    "        \n",
    "        chi2, p_value, _, _ = stats.chi2_contingency(contingency_table_gender)\n",
    "        \n",
    "        print(f\"\\nChi-Squared Statistic: {chi2:.2f}, P-value: {p_value}\")\n",
    "        \n",
    "        if p_value < alpha:\n",
    "            print(\"\\nConclusion: Reject the null hypothesis.\")\n",
    "            print(\"Finding: There is a statistically significant difference in claim risk between men and women.\")\n",
    "            print(\"Recommendation: Gender can be considered a valid factor in our risk models. Further analysis is needed to quantify the effect on premiums.\")\n",
    "        else:\n",
    "            print(\"\\nConclusion: Fail to reject the null hypothesis.\")\n",
    "            print(\"Finding: No significant evidence of a risk difference between men and women in this dataset.\")\n",
    "    else:\n",
    "        print(\"Skipping test: Not enough distinct gender categories ('M', 'F') found after cleaning.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
